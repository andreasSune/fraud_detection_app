#  D√©tection de Fraudes par Carte de Cr√©dit

![Python](https://img.shields.io/badge/Python-3.9-blue) ![Scikit-learn](https://img.shields.io/badge/Scikit--learn-1.0-orange) ![XGBoost](https://img.shields.io/badge/XGBoost-Latest-green) ![License](https://img.shields.io/badge/License-MIT-green)

Syst√®me de d√©tection de fraudes utilisant des techniques avanc√©es de Machine Learning pour identifier les transactions suspectes avec une pr√©cision de 85% (AUPRC) et un recall de 86%.

**Objectif :** Maximiser la d√©tection des fraudes tout en minimisant les faux positifs pour r√©duire les pertes financi√®res et maintenir une exp√©rience client optimale.

---

## R√©sultats Cl√©s

- ‚úÖ **AUPRC de 0.87** (XGBoost) - M√©trique principale pour donn√©es d√©s√©quilibr√©es
- ‚úÖ **Precision 85% / Recall 86%** - Excellent √©quilibre d√©tection/faux positifs
- ‚úÖ **Am√©lioration √ó4** d'Isolation Forest via feature selection
- ‚úÖ Pipeline ML complet et reproductible avec GridSearchCV



---

##  Contexte et Dataset

### Source
**Kaggle Credit Card Fraud Detection Dataset**
- URL : https://www.kaggle.com/mlg-ulb/creditcardfraud

### Caract√©ristiques
- **284,807 transactions** sur 2 jours (septembre 2013)
- **492 fraudes** (0.172% du total - d√©s√©quilibre extr√™me 1:577)
- **30 features** : 28 composantes PCA (V1-V28) + Time + Amount
- **Anonymisation** : Features originales transform√©es par PCA pour confidentialit√©

### D√©fi Principal
Le **d√©s√©quilibre extr√™me** des classes (99.828% l√©gitimes vs 0.172% fraudes) n√©cessite :
- M√©triques adapt√©es (AUPRC > Accuracy)
- Techniques de r√©√©quilibrage (SMOTE)
- Validation rigoureuse (stratified split)

---

##  M√©thodologie

### 1Ô∏è‚É£ Analyse Exploratoire des Donn√©es (EDA)

#### Distribution de Amount par Classe

![Amount Distribution](img/01_amount_distribution.png)

**Observations :**
- Les transactions **l√©gitimes** ont une m√©diane de ~22‚Ç¨
- Les transactions **frauduleuses** ont des montants plus variables
- Pr√©sence d'outliers importants dans les deux classes
- **RobustScaler** choisi pour sa robustesse aux valeurs extr√™mes

#### Analyse Temporelle des Fraudes

![Temporal Analysis](img/02_temporal_analysis.png)

**D√©couvertes cl√©s :**
-  **Pic de fraudes entre 22h-4h** (p√©riode nocturne)
-  Taux de fraude **2.3√ó sup√©rieur** pendant les heures de nuit
-  Distribution relativement uniforme sur les 2 jours
-  **Insight** : Cr√©ation de feature `Is_Night` pour capturer ce pattern

#### Analyse des Composantes PCA

![PCA Analysis](img/03_pca_variance_analysis.png)

**Insights :**
- **Variance ‚â† Pertinence** pour la classification
  - V1 (haute variance) mais faible corr√©lation avec fraude
  - V14 (variance mod√©r√©e) mais **forte corr√©lation** avec fraude (-0.35)
- **Top 3 features discriminantes** : V14, V17, V12
- La PCA optimise la variance, pas la discrimination des classes

---

### 2Ô∏è‚É£ Preprocessing et Feature Engineering

#### Standardisation
```python
# RobustScaler pour Amount (robuste aux outliers)
scaler = RobustScaler()
Amount_scaled = scaler.fit_transform(Amount)
```

#### Feature Engineering Temporel

![Temporal Features](img/04_temporal_features_analysis.png)

**Features cr√©√©es (10 au total) :**

| Feature | Description | Importance |
|---------|-------------|-----------|
| `Hour_sin`, `Hour_cos` | Encodage cyclique de l'heure (24h) | ‚≠ê‚≠ê‚≠ê |
| `Is_Night` | Indicateur p√©riode √† risque (22h-6h) | ‚≠ê‚≠ê‚≠ê |
| `Is_Morning` | P√©riode matinale (6h-12h) | ‚≠ê |
| `Is_Afternoon` | Apr√®s-midi (12h-18h) | ‚≠ê |
| `Is_Evening` | Soir√©e (18h-22h) | ‚≠ê |
| `Day` | Jour depuis d√©but (0-2) | ‚≠ê |
| `Transactions_per_hour` | Densit√© de transactions | ‚≠ê‚≠ê |
| `Time_normalized` | Time normalis√© (0-1) | ‚≠ê |

**S√©lection finale :** 4 features temporelles retenues (importance ‚â• 0.1)
- `Hour_sin`, `Hour_cos`, `Is_Night`, `Transactions_per_hour`

![Feature Importance](img/05_temporal_features_importance.png)

#### Pipeline de Preprocessing Final

**Features finales : 32**
- 28 composantes PCA (V1-V28)
- 1 Amount (standardis√© avec RobustScaler)
- 4 features temporelles s√©lectionn√©es

---

### 3Ô∏è‚É£ Strat√©gie de Gestion du D√©s√©quilibre

#### Pour Mod√®les Supervis√©s
- **SMOTE (Synthetic Minority Over-sampling Technique)**
  - Appliqu√© APR√àS split train/validation (√©vite data leakage)
  - √âquilibrage : 181,961 l√©gitimes ‚Üí 181,961 fraudes synth√©tiques
  - Validation sur donn√©es r√©elles (sans SMOTE)

#### Pour Mod√®les d'Anomalies
- **Pas de SMOTE** (apprennent ce qui est "normal")
- Contamination ajust√©e : 0.005 ( plus permissif )
- **Feature selection agressive** : R√©duction √† 15 features pour IF/LOF

---

### 4Ô∏è‚É£ Mod√©lisation

#### Mod√®les Test√©s

**Approche Supervis√©e (avec SMOTE) :**
1. **Random Forest** - Baseline robuste
2. **XGBoost** - Mod√®le avanc√© avec boosting

**Approche Non-Supervis√©e (d√©tection d'anomalies) :**
3. **Isolation Forest** - Isolation g√©om√©trique
4. **Local Outlier Factor (LOF)** - D√©tection bas√©e sur densit√© locale

#### Optimisation des Hyperparam√®tres

**GridSearchCV** avec :
- **3-fold cross-validation** stratifi√©e
- **Scoring : `average_precision`** (AUPRC - m√©trique cl√©)

**Grilles de recherche :**

```python
# Random Forest
{
    'n_estimators': [100, 200],
    'max_depth': [10, 20, None],
    'min_samples_split': [2, 5],
    'min_samples_leaf': [1, 2]
}

# XGBoost
{
    'n_estimators': [100, 200],
    'max_depth': [3, 5, 7],
    'learning_rate': [0.01, 0.1, 0.3],
    'subsample': [0.8, 1.0],
    'colsample_bytree': [0.8, 1.0]
}
```

---

### 5Ô∏è‚É£ M√©triques d'√âvaluation

**Pourquoi pas Accuracy ?**
Avec un d√©s√©quilibre de 577:1 (99.83% l√©gitimes)
```
Mod√®le pr√©dit tout l√©gitime :
‚Üí Accuracy = 99.83% ‚ùå (trompeur !)
‚Üí AUPRC = 0.00 ‚úÖ (refl√®te vraie performance)
```

**M√©triques utilis√©es :**
- **AUPRC** (Area Under Precision-Recall Curve) - M√©trique principale car adapt√©es aux datasets d√©s√©quilibr√©s; plus s√©v√®re et honn√™te
- **AUC-ROC** (Area Under ROC Curve)
- **Precision** : Parmi les alertes, combien sont vraies ?
- **Recall** : Parmi les fraudes, combien sont d√©tect√©es ?
- **F1-Score** : Moyenne harmonique Precision/Recall

---

##  R√©sultats D√©taill√©s

### Performance sur Train/Validation

| Mod√®le | AUPRC | AUC-ROC | Precision | Recall | F1-Score |
|--------|-------|---------|-----------|--------|----------|
| **XGBoost** ‚≠ê | **0.8304** | **0.9575** | **85%** | **81%** | **0.83** |
| Random Forest | 0.8050 | 0.9643 | 87% | 77% | 0.82 |
| Isolation Forest | 0.5190 | 0.9596 | 26% | 74% | 0.38 |
| LOF | 0.0020 | 0.4714 | 1% | 2% | 0.01 |

### üèÜ Mod√®le Retenu : XGBoost

**Meilleurs hyperparam√®tres (GridSearchCV) :**
```python
{
    'colsample_bytree': 1.0,
    'learning_rate': 0.3,
    'max_depth': 5,
    'n_estimators': 200,
    'subsample': 1.0
}
```

**Justification du choix :**
- ‚úÖ **Meilleur AUPRC** (0.8304 sur validation) - M√©trique cl√© pour d√©s√©quilibre
- ‚úÖ **√âquilibre optimal** Precision (85%) / Recall (81%)
- ‚úÖ **Robuste** : Performance stable sur validation
- ‚úÖ **Scalable** : Temps d'inf√©rence acceptable pour production

**Classification Report (Validation Set) :**
```
                 precision    recall  f1-score   support
    L√©gitime       1.00      1.00      1.00     45490
    Fraude         0.85      0.81      0.83        79

    accuracy                           1.00     45569
   macro avg       0.93      0.90      0.92     45569
weighted avg       1.00      1.00      1.00     45569
```

---

##  Validation Finale sur Test Set

### M√©thodologie de Validation

Pour garantir une √©valuation objective et √©viter tout biais d'optimisation, le mod√®le a √©t√© √©valu√© sur un **test set compl√®tement isol√©** :

- **20% des donn√©es** (56,962 transactions)
- **Split stratifi√©** (pr√©serve le ratio 0.172% de fraudes)
- **Aucune fuite de donn√©es** : Le test set n'a jamais √©t√© vu pendant l'entra√Ænement ou l'optimisation
- **Preprocessing identique** : Utilisation du m√™me scaler et features que le train set

### R√©sultats sur Test Set 

![Test Metrics Comparison](img/08_test_metrics_comparison.png)

| Mod√®le | AUPRC | AUC-ROC | Precision | Recall | F1-Score |
|--------|-------|---------|-----------|--------|----------|
| **XGBoost** üèÜ | **0.8688** | **0.9807** | **84.8%** | **85.7%** | **0.853** |
| Random Forest | 0.8634 | 0.9725 | 88.0% | 82.7% | 0.853 |
| Isolation Forest | 0.5024 | 0.9553 | 24.1% | 80.6% | 0.371 |

###  Analyse Comparative Train vs Test

| Mod√®le | AUPRC Train | AUPRC Test | √âcart | Conclusion |
|--------|-------------|------------|-------|------------|
| **XGBoost** | 0.8304 | **0.8688** | **+0.0384** |  **Am√©lioration sur test** |
| Random Forest | 0.8050 | 0.8634 | +0.0584 |  Excellente g√©n√©ralisation |
| Isolation Forest | 0.5190 | 0.5024 | -0.0166 |  Performance stable |

** Observation cl√© :** XGBoost **surperforme m√™me sur le test set**, d√©montrant une excellente capacit√© de g√©n√©ralisation et l'**absence d'overfitting**.

### Matrices de Confusion

![Confusion Matrices Test](img/09_test_confusion_matrices.png)

#### XGBoost sur Test Set (98 fraudes r√©elles)

```
                    Pr√©dit L√©gitime | Pr√©dit Fraude
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Vraie L√©gitime           56,849     |      15
Vraie Fraude                14      |      84
```



**Points forts :**
- **85.7% de recall** : D√©tection de la grande majorit√© des fraudes
- **Seulement 15 faux positifs** sur 56,864 transactions l√©gitimes
- **Taux de FP extr√™mement faible** : 0.026% (excellent pour l'exp√©rience client)

### Courbes de Performance D√©taill√©es

#### Courbes ROC
![ROC Curves](img/10_test_roc_curves.png)

**XGBoost : AUC-ROC = 0.9807**
- Excellente discrimination globale entre fraudes et l√©gitimes
- Courbe tr√®s proche du coin sup√©rieur gauche (performance optimale)
- Nettement sup√©rieur au mod√®le al√©atoire (ligne diagonale)

#### Courbes Precision-Recall
![PR Curves](img/11_test_precision_recall_curves.png)

**XGBoost : AUPRC = 0.8688**
- La courbe reste √©lev√©e sur tout le spectre Recall
- D√©montre la robustesse m√™me avec variation du seuil de d√©cision
- Largement au-dessus de la baseline (taux de fraude = 0.172%)

** Insight :** La forme de la courbe PR indique que le mod√®le maintient une **haute precision m√™me en augmentant le recall**, confirmant son excellente calibration.


---

##  Analyse Approfondie : Feature Selection

### Impact Critique sur Isolation Forest

**Exp√©rimentation :**

| Configuration | Features | Contamination | AUPRC | Am√©lioration |
|--------------|----------|---------------|-------|--------------|
| Baseline | 34 | 0.002 | 0.13 | - |
| **Optimis√©e** | **15** | **0.005** | **0.52** | **√ó4** üìà |

**D√©couverte cl√© :** 

Les algorithmes d'anomalies bas√©s sur la g√©om√©trie sont **extr√™mement sensibles** √† la dimensionnalit√©. La r√©duction de 34 ‚Üí 15 features am√©liore drastiquement la capacit√© d'Isolation Forest √† isoler les anomalies.

**Features s√©lectionn√©es pour IF/LOF (15) :**
```
V17, V12, V14, V16, V11, V10, V7, V4, V18, V9, 
V2, Hour_sin, V21, V26, V3
```

**M√©thode de s√©lection :**
- Random Forest rapide (50 estimateurs) pour calculer l'importance
- Conservation des top 15 features par importance
- Application UNIQUEMENT aux mod√®les d'anomalies (pas aux supervis√©s)

---

## ‚ùå √âchec de LOF : Analyse Instructive

### R√©sultat Final
- **AUPRC : 0.002** (quasi-nul)
- **AUC-ROC : 0.47** (pire qu'un mod√®le al√©atoire √† 0.50)
- **Precision : 1%** (99% de faux positifs)
- Aucune am√©lioration malgr√© feature selection et ajustements

### Hypoth√®se Expliquant l'√âchec

**Les fraudes de ce dataset NE SONT PAS des outliers de densit√© locale.**

#### Observations

1. **LOF √©choue m√™me avec optimisations :**
   - ‚úÖ Feature selection agressive (34 ‚Üí 15 features)
   - ‚úÖ Contamination ajust√©e (0.002 ‚Üí 0.005)
   - ‚úÖ Hyperparam√®tres test√©s (n_neighbors: 20, 50, 100)
   - ‚ùå **R√©sultat : Aucune am√©lioration**

2. **Implication :** 

Les transactions frauduleuses ont une **densit√© locale similaire** aux transactions l√©gitimes. Elles ne se distinguent pas par leur "isolement g√©om√©trique" mais par des **patterns comportementaux complexes** et des **interactions non-lin√©aires** entre features.

3. **Confirmation par contraste :**

| Mod√®le | Approche | AUPRC |
|--------|----------|-------|
| LOF | Distance & Densit√© | 0.002 ‚ùå |
| XGBoost | Patterns & Interactions | 0.830 ‚úÖ |

**‚ûú XGBoost r√©ussit car il capture des interactions complexes entre features, pas juste des distances.**

---

## Insights M√©thodologiques

### 1. D√©tection de Fraude ‚â† D√©tection d'Anomalies

Ce projet d√©montre empiriquement que **fraude** et **anomalie g√©om√©trique** ne sont pas synonymes :

```
Anomalie g√©om√©trique : Point isol√© dans l'espace feature
Fraude : Combinaison subtile de patterns comportementaux

Exemple :
- Transaction de 50‚Ç¨ √† 2h du matin depuis Paris
- Individuellement : Rien d'anormal
- Combinaison : Pattern suspect (si client habituel : 100‚Ç¨ √† 14h depuis Lyon)
```

**Cons√©quence :**
- ‚úÖ Mod√®les supervis√©s (XGBoost/RF) : Apprennent ces combinaisons ‚Üí Succ√®s
- ‚ùå Mod√®les g√©om√©triques (LOF) : Ne d√©tectent pas ces patterns ‚Üí √âchec



### 4. Trade-off Precision vs Recall

**Interpr√©tation business des r√©sultats :**

#### XGBoost (Precision 85%, Recall 81%)
```
Sur 100 alertes g√©n√©r√©es :
- 85 sont de vraies fraudes ‚úÖ
- 15 sont des faux positifs ‚ùå

Sur 100 vraies fraudes :
- 81 sont d√©tect√©es ‚úÖ
- 19 passent inaper√ßues ‚ùå

‚ûú Excellent √©quilibre pour production
‚ûú Co√ªts op√©rationnels ma√Ætris√©s (peu de FP)
‚ûú Taux de d√©tection √©lev√© (81%)
```

#### Isolation Forest (Precision 26%, Recall 74%)
```
Sur 100 alertes g√©n√©r√©es :
- 24 sont de vraies fraudes ‚úÖ
- 76 sont des faux positifs ‚ùå


```

---

## Limites et Axes d'Am√©lioration

### Limites Identifi√©es

#### 1. Dataset Acad√©mique
-  **Pas d'ID client** : Impossible de personnaliser la d√©tection par profil
-  **Features anonymis√©es (PCA)** : Difficult√© d'interpr√©tation m√©tier
-  **P√©riode limit√©e** : 2 jours seulement (pas de patterns long-terme)
-  **Pas de contexte** : G√©olocalisation, type de marchand, device absents

**Impact :** Le mod√®le d√©tecte des patterns **globaux**, pas des d√©viations par rapport au comportement **individuel** de chaque client.

#### 2. Mod√®le de D√©tection Globale

**En production r√©elle, les banques utilisent :**
```
Niveau 1 : Mod√®le global (comme notre XGBoost)
    ‚Üì
Niveau 2 : Mod√®le par segment client
    (√©tudiants, retrait√©s, business)
    ‚Üì
Niveau 3 : Profil individuel
    (baseline personnalis√© par client)
```

**Notre mod√®le = Niveau 1 uniquement**

#### 3. Absence de Features Contextuelles

**Missing features critiques :**
-  **G√©olocalisation** : Pays, ville, distance depuis derni√®re transaction
-  **Type de marchand** : Cat√©gorie, r√©putation, historique
-  **Historique client** : Montant moyen, fr√©quence, patterns habituels
-  **Device** : Appareil utilis√©, IP, navigateur
-  **Contexte temporel** : Jour de la semaine, p√©riode du mois (salaire)

### Am√©liorations Possibles

#### Court Terme (avec ce dataset)

1. **Ensembling Avanc√©**
   ```python
   # Stacking : Combiner XGBoost + RF + IF
   stacking_model = StackingClassifier(
       estimators=[('xgb', xgboost), ('rf', random_forest), ('if', iso_forest)],
       final_estimator=LogisticRegression()
   )
   ```
   Gain attendu : +2-3% AUPRC

2. **Calibration des Probabilit√©s**
   ```python
   from sklearn.calibration import CalibratedClassifierCV
   calibrated_xgb = CalibratedClassifierCV(xgboost, cv=3)
   ```
   Meilleure interpr√©tation des scores de confiance

3. **Feature Engineering Avanc√©**
   - Ratios entre composantes PCA (V14/V17, etc.)
   - Polynomials features (interactions V14√óHour_sin)
   - Agr√©gations temporelles (rolling statistics)

#### Long Terme (avec donn√©es r√©elles)

1. **Profiling Client**
   - Baseline personnalis√© par client
   - D√©tection de d√©viations individuelles
   - Mod√®les hi√©rarchiques (global ‚Üí segment ‚Üí individuel)

2. **Features Contextuelles**
   - API de g√©olocalisation
   - Cat√©gorisation des marchands
   - Device fingerprinting

3. **Apprentissage Continu**
   - Online learning : Mise √† jour du mod√®le en continu
   - Feedback loop : Int√©grer les retours analystes
   - D√©tection de concept drift

4. **Explicabilit√© (XAI)**
   - SHAP values pour chaque pr√©diction
   - Interface analystes : "Pourquoi cette transaction est suspecte ?"
   - Conformit√© r√©glementaire (GDPR : droit √† l'explication)

---



##  Impact Business

### Sc√©nario de D√©ploiement

**Hypoth√®ses :**
- Volume : **100,000 transactions/jour**
- Taux de fraude r√©el : **0.17%** (170 fraudes/jour)
- Montant moyen fraude : **150‚Ç¨**

### Sans Syst√®me de D√©tection
```
Pertes quotidiennes :
170 fraudes √ó 150‚Ç¨ = 25,500‚Ç¨/jour

Pertes annuelles :
25,500‚Ç¨ √ó 365 = 9,307,500‚Ç¨/an
```

### Avec XGBoost (Recall 81%)
```
Fraudes d√©tect√©es :
170 √ó 81% = 138 fraudes/jour

Pertes √©vit√©es :
138 √ó 150‚Ç¨ = 20,700‚Ç¨/jour

Pertes r√©siduelles :
32 fraudes non d√©tect√©es √ó 150‚Ç¨ = 4,800‚Ç¨/jour

√âconomies annuelles :
20,700‚Ç¨ √ó 365 = 7,555,500‚Ç¨/an üí∞
```
